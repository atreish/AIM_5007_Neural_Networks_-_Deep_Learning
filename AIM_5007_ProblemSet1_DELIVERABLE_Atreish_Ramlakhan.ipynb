{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Atreish Ramlakhan\n",
    "AIM 5007: Neural Networks and Deep Learning \n",
    "Fall 2021\n",
    "Problem Set #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use appropriate pandas data import, insert the file path\n",
    "df = pd.read_csv('')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define X our (x,y) points and y our classifications for analysis\n",
    "X = df[df.columns[1:3]].to_numpy()\n",
    "y = df[df.columns[3]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determines the class of the value \"a\" as either 1, -1 based on the formula with weights\n",
    "def sign(a):\n",
    "    if a >= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "#function casts list for each tp, fp, tn, fn and determines accuracy\n",
    "def confusion_matrix(y_predicted, y_actual, prints = False):\n",
    "    true_positive = [] #create lists \n",
    "    true_negative = []\n",
    "    false_positive = []\n",
    "    false_negative = []\n",
    "    #if the input classification vector and predicted class match or not, append the appropriate vector\n",
    "    for i in range(len(y_actual)):\n",
    "        if (y_actual[i] == 1) and (y_predicted[i] == 1): \n",
    "            true_positive.append(i)\n",
    "        elif (y_actual[i] == -1) and (y_predicted[i] == -1):\n",
    "            true_negative.append(i)\n",
    "        elif (y_actual[i] == -1) and (y_predicted[i] == 1):\n",
    "            false_positive.append(i)\n",
    "        elif (y_actual[i] == 1) and (y_predicted[i] == -1):\n",
    "            false_negative.append(i)\n",
    "    #print each subset of a confusion matrix and the algorithm's overall accuracy \n",
    "    if prints:\n",
    "        print(\"\\nTrue Positive Count:\", len(true_positive))\n",
    "        print(\"False Positive Count:\", len(false_positive))\n",
    "        print(\"False Negative Count:\", len(false_negative))\n",
    "        print(\"True Negative Count:\", len(true_negative))\n",
    "        print(\"\\nAccuracy:\", 100*(len(true_positive) + len(true_negative))/len(y_actual), \"%\")\n",
    "    return np.array(true_positive), np.array(false_positive), np.array(false_negative), np.array(true_negative)\n",
    "\n",
    "#initialize weights to be a random vector of 3 coefficients\n",
    "w = (2 * np.random.random_sample(3)) - 1\n",
    "\n",
    "\n",
    "\"\"\"The following function takes in our X or points and an initial weight vector and outputs the predicted class \n",
    "vector based on the initial formula specified on each point in our dataframe\"\"\"\n",
    "\n",
    "def perceptron_predict(X, w):\n",
    "    y_predicted = np.zeros(X.shape[0])\n",
    "    for i in range(X.shape[0]):\n",
    "        y_predicted[i] = sign((w[0]*X[i,0]) + (w[1]*X[i,1]) + w[2]) #initial weight function   \n",
    "    return y_predicted\n",
    "\n",
    "\"\"\" Once we have used the initial weight vector we will now update the weights at the next iteration based on \n",
    "the formulas specified for each element of the weight vector, we will be sure to begin from an incorrectly \n",
    "classified index  \"\"\"\n",
    "\n",
    "def perceptron_update(X, y, false_indices, w_old):\n",
    "    i = int(np.random.choice(false_indices))\n",
    "    w0 = w_old[0] + (y[i]*X[i,0]) #updated weight function\n",
    "    w1 = w_old[1] + (y[i]*X[i,1])\n",
    "    w2 = w_old[2] + y[i]\n",
    "    return np.array([w0, w1, w2])\n",
    "\n",
    "\"\"\"Now that we have our initial classification function, the perceptron prediction, and the update rule in \n",
    "place, apply all functions in our perceptron and institute a maximum of 10,000 iterations. This will output\n",
    "the final weights or coefficients of the final classification forumla for all our points, as well as the \n",
    "confusion matrix, and accuracy of the model\"\"\"\n",
    "\n",
    "def perceptron_train(X, y, w_initial, max_iterations = 10000):\n",
    "    iterations = 0\n",
    "    w = w_initial\n",
    "    \n",
    "    while iterations < max_iterations:\n",
    "        y_predicted = perceptron_predict(X, w)  \n",
    "        true_pos, false_pos, false_neg, true_neg = confusion_matrix(y_predicted, y)\n",
    "        accuracy = (len(true_pos) + len(true_neg))/len(y)\n",
    "        if accuracy == 1:\n",
    "            break\n",
    "            \n",
    "        #What are the false indicies?\n",
    "        false_indices = np.concatenate((false_pos, false_neg))\n",
    "        \n",
    "        #Apply the weight update function defined above to reduced falsely classified points\n",
    "        w = perceptron_update(X, y, false_indices, w)\n",
    "        iterations += 1\n",
    "        \n",
    "    if accuracy == 1:\n",
    "        print(\"Final Weights with Bias:\",\"\\n\\n\", w[0],\"\\n\",w[1],\"\\n\",w[2])\n",
    "        print(\"\\nIterations Used:\", iterations)\n",
    "        print(\"\\nFinal Weight Vector:\", w)\n",
    "        \n",
    "    else:\n",
    "        print(\"ERROR: Unable to converge within iteration limit. Data may not be linearly separable.\")\n",
    "        print(\"\\nIterations Used:\", iterations)\n",
    " \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = (2 * np.random.random_sample(3)) - 1\n",
    "perc_train = perceptron_train(X, y, weights)\n",
    "y_predicted = perceptron_predict(X, perc_train)\n",
    "tp, fp, fn, tn = confusion_matrix(y_predicted, y, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
